#!/usr/bin/env python3
"""
OpenAgent - Agente de IA Local 100% Open Source
Um sistema completo de agente LLM local semelhante ao Opencode, mas 100% independente.
"""

import os
import sys
import json
import argparse
import threading
import time
from pathlib import Path
from typing import Dict, List, Any, Optional

# Importar mÃ³dulos locais
from .model_manager import ModelManager
from .llm_server import LLMServer
from .tools import ToolRegistry

class OpenAgent:
    """Classe principal do OpenAgent"""
    
    def __init__(self, config_path: str = "./config"):
        self.config_path = Path(config_path)
        self.config_path.mkdir(exist_ok=True)
        
        self.model_manager = ModelManager(str(self.config_path / "models"))
        self.llm_server = LLMServer()
        self.tool_registry = ToolRegistry()
        
        self.config_file = self.config_path / "openagent.json"
        self.config = self._load_config()
        
        self.running = False
        self.server_thread = None
    
    def _load_config(self) -> Dict:
        """Carrega configuraÃ§Ã£o do arquivo"""
        if self.config_file.exists():
            with open(self.config_file, 'r') as f:
                return json.load(f)
        return {
            "server": {
                "host": "127.0.0.1",
                "port": 1234
            },
            "ui": {
                "theme": "dark",
                "show_models_info": True
            },
            "models": {
                "auto_load_last": True,
                "preferred_source": "all"
            }
        }
    
    def _save_config(self):
        """Salva configuraÃ§Ã£o no arquivo"""
        with open(self.config_file, 'w') as f:
            json.dump(self.config, f, indent=2)
    
    def start_server(self) -> bool:
        """Inicia o servidor LLM"""
        try:
            self.llm_server.start()
            self.running = True
            return True
        except Exception as e:
            print(f"âŒ Erro ao iniciar servidor: {e}")
            return False
    
    def stop_server(self):
        """Para o servidor LLM"""
        if self.running:
            self.llm_server.stop()
            self.running = False
    
    def search_models_interactive(self, query: str = "", source: str = "all"):
        """Busca modelos de forma interativa"""
        print(f"ğŸ” Buscando modelos{' em ' + source if source != 'all' else ''}...")
        
        models = self.model_manager.search_models(query, source)
        
        if not models:
            print("âŒ Nenhum modelo encontrado.")
            return
        
        print(f"\nğŸ“‹ Encontrados {len(models)} modelos:\n")
        
        for i, model in enumerate(models, 1):
            capabilities = model.get("capabilities", {})
            caps_str = []
            
            if capabilities.get("tools"): caps_str.append("ğŸ”§ Tools")
            if capabilities.get("reasoning"): caps_str.append("ğŸ§  Reasoning")
            if capabilities.get("vision"): caps_str.append("ğŸ‘ï¸ Vision")
            if capabilities.get("code"): caps_str.append("ğŸ’» Code")
            if capabilities.get("chat"): caps_str.append("ğŸ’¬ Chat")
            if capabilities.get("multimodal"): caps_str.append("ğŸ¨ Multimodal")
            
            caps_display = " | ".join(caps_str) if caps_str else "ğŸ“ Text"
            
            print(f"{i:2d}. ğŸ“¦ {model['name']}")
            print(f"     ğŸ“ {model['description'][:80]}{'...' if len(model['description']) > 80 else ''}")
            print(f"     ğŸ“Š {model.get('size', 'Unknown')} | â¬‡ï¸ {model.get('downloads', 0):,} downloads | â¤ï¸ {model.get('likes', 0):,}")
            print(f"     ğŸ·ï¸ {model.get('source', 'unknown').title()} | {caps_display}")
            print()
        
        return models
    
    def download_model_interactive(self, model_id: str) -> bool:
        """Baixa um modelo de forma interativa"""
        print(f"â¬‡ï¸ Iniciando download do modelo: {model_id}")
        
        def progress_callback(message):
            print(f"   {message}")
        
        success = self.model_manager.download_model(model_id, progress_callback)
        
        if success:
            print(f"âœ… Modelo {model_id} baixado com sucesso!")
            
            # Pergunta se quer carregar o modelo
            response = input("ğŸ”„ Deseja carregar este modelo agora? (s/N): ").strip().lower()
            if response in ['s', 'sim', 'y', 'yes']:
                return self.load_model_interactive(model_id)
        else:
            print(f"âŒ Falha ao baixar modelo {model_id}")
        
        return success
    
    def load_model_interactive(self, model_id: str) -> bool:
        """Carrega um modelo de forma interativa"""
        print(f"ğŸ”„ Carregando modelo: {model_id}")
        
        success = self.model_manager.load_model(model_id)
        
        if success:
            print(f"âœ… Modelo {model_id} carregado com sucesso!")
            self.config["models"]["last_loaded"] = model_id
            self._save_config()
        else:
            print(f"âŒ Falha ao carregar modelo {model_id}")
        
        return success
    
    def list_local_models(self):
        """Lista modelos locais"""
        models = self.model_manager.list_local_models()
        active_model = self.model_manager.get_active_model()
        
        if not models:
            print("ğŸ“­ Nenhum modelo local encontrado.")
            return
        
        print(f"\nğŸ“š Modelos Locais ({len(models)}):\n")
        
        for i, model in enumerate(models, 1):
            status = "ğŸŸ¢ ATIVO" if model["id"] == active_model else "âšª INATIVO"
            size_mb = model.get("size", 0) / (1024 * 1024)
            
            print(f"{i:2d}. {status} ğŸ“¦ {model['id']}")
            print(f"     ğŸ“ {model['path']}")
            print(f"     ğŸ“Š {size_mb:.1f} MB")
            print()
    
    def interactive_shell(self):
        """Inicia o shell interativo"""
        print("\nğŸš€ OpenAgent - Shell Interativo")
        print("=" * 50)
        print("Comandos disponÃ­veis:")
        print("  /search [query] - Buscar modelos")
        print("  /download [model] - Baixar modelo")
        print("  /load [model] - Carregar modelo")
        print("  /models - Listar modelos locais")
        print("  /status - Mostrar status")
        print("  /help - Ajuda")
        print("  /quit - Sair")
        print("=" * 50)
        
        messages = [
            {
                "role": "system",
                "content": (
                    "VocÃª Ã© o OpenAgent, um assistente de IA local com acesso a ferramentas. "
                    "VocÃª pode ajudar com tarefas como criar/editar arquivos, executar comandos, "
                    "buscar informaÃ§Ãµes e processar imagens. Use as ferramentas disponÃ­veis "
                    "sempre que apropriado."
                )
            }
        ]
        
        while True:
            try:
                user_input = input("\nğŸ§‘ VocÃª: ").strip()
                
                if not user_input:
                    continue
                
                # Comandos do sistema
                if user_input.startswith('/'):
                    self._handle_command(user_input)
                    continue
                
                # Processa mensagem com a IA
                messages.append({"role": "user", "content": user_input})
                
                response = self._generate_response(messages)
                
                if response:
                    messages.append({"role": "assistant", "content": response})
                    print(f"\nğŸ¤– OpenAgent: {response}")
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ AtÃ© logo!")
                break
            except Exception as e:
                print(f"\nâŒ Erro: {e}")
    
    def _handle_command(self, command: str):
        """Lida com comandos do shell"""
        parts = command.split()
        cmd = parts[0].lower()
        
        if cmd == '/search':
            query = ' '.join(parts[1:]) if len(parts) > 1 else ""
            self.search_models_interactive(query)
        
        elif cmd == '/download':
            if len(parts) < 2:
                print("âŒ Uso: /download <model_id>")
                return
            
            model_id = ' '.join(parts[1:])
            self.download_model_interactive(model_id)
        
        elif cmd == '/load':
            if len(parts) < 2:
                print("âŒ Uso: /load <model_id>")
                return
            
            model_id = ' '.join(parts[1:])
            self.load_model_interactive(model_id)
        
        elif cmd == '/models':
            self.list_local_models()
        
        elif cmd == '/status':
            self._show_status()
        
        elif cmd == '/help':
            self._show_help()
        
        elif cmd in ['/quit', '/exit', '/q']:
            print("ğŸ‘‹ Encerrando OpenAgent...")
            self.stop_server()
            sys.exit(0)
        
        else:
            print(f"âŒ Comando desconhecido: {cmd}")
            print("Digite /help para ver os comandos disponÃ­veis.")
    
    def _generate_response(self, messages: List[Dict]) -> Optional[str]:
        """Gera resposta usando o modelo ativo"""
        active_model = self.model_manager.get_active_model()
        
        if not active_model:
            print("âš ï¸ Nenhum modelo carregado. Use /load <modelo> para carregar um modelo.")
            return None
        
        try:
            # SimulaÃ§Ã£o de geraÃ§Ã£o (na implementaÃ§Ã£o real, usaria o modelo)
            time.sleep(1)
            
            # Extrai a Ãºltima mensagem do usuÃ¡rio
            user_msg = messages[-1]["content"] if messages else ""
            
            # Respostas simuladas baseadas em padrÃµes
            if "criar arquivo" in user_msg.lower():
                return "Posso ajudar vocÃª a criar um arquivo. Qual o nome e conteÃºdo do arquivo que deseja criar?"
            elif "executar" in user_msg.lower() or "rodar" in user_msg.lower():
                return "Posso executar comandos para vocÃª. Qual comando deseja executar?"
            elif "listar" in user_msg.lower() or "mostrar" in user_msg.lower():
                return "Posso listar arquivos e diretÃ³rios. Qual caminho deseja explorar?"
            else:
                return f"Entendi sua solicitaÃ§Ã£o. Como assistente OpenAgent, posso ajudar com diversas tarefas usando as ferramentas disponÃ­veis. O que vocÃª gostaria que eu fizesse especificamente?"
        
        except Exception as e:
            print(f"âŒ Erro ao gerar resposta: {e}")
            return None
    
    def _show_status(self):
        """Mostra status atual do sistema"""
        print("\nğŸ“Š Status do OpenAgent:")
        print(f"   ğŸ–¥ï¸ Servidor: {'ğŸŸ¢ Online' if self.running else 'ğŸ”´ Offline'}")
        print(f"   ğŸ“¦ Modelo Ativo: {self.model_manager.get_active_model() or 'Nenhum'}")
        print(f"   ğŸ“ DiretÃ³rio de Trabalho: {os.getcwd()}")
        print(f"   ğŸ“š Modelos Locais: {len(self.model_manager.list_local_models())}")
    
    def _show_help(self):
        """Mostra ajuda"""
        print("\nğŸ“– Ajuda do OpenAgent:")
        print("\nğŸ”§ Comandos do Sistema:")
        print("   /search [query]     - Buscar modelos disponÃ­veis")
        print("   /download <model>   - Baixar um modelo")
        print("   /load <model>       - Carregar um modelo")
        print("   /models             - Listar modelos locais")
        print("   /status             - Mostrar status do sistema")
        print("   /help               - Mostrar esta ajuda")
        print("   /quit               - Sair do OpenAgent")
        print("\nğŸ’¬ Exemplos de uso:")
        print("   Crie um arquivo Python com hello world")
        print("   Liste os arquivos no diretÃ³rio atual")
        print("   Execute o comando 'python --version'")
        print("   Busque por 'mistral' para encontrar modelos")

def main():
    """FunÃ§Ã£o principal"""
    parser = argparse.ArgumentParser(description="OpenAgent - Agente de IA Local")
    parser.add_argument("--config", default="./config", help="DiretÃ³rio de configuraÃ§Ã£o")
    parser.add_argument("--server-only", action="store_true", help="Iniciar apenas o servidor")
    parser.add_argument("--port", type=int, default=1234, help="Porta do servidor")
    parser.add_argument("--host", default="127.0.0.1", help="Host do servidor")
    
    args = parser.parse_args()
    
    # Inicia OpenAgent
    agent = OpenAgent(args.config)
    
    # Configura servidor se especificado
    if args.host != "127.0.0.1" or args.port != 1234:
        agent.llm_server.host = args.host
        agent.llm_server.port = args.port
    
    print("ğŸš€ Iniciando OpenAgent...")
    
    # Inicia servidor
    if not agent.start_server():
        print("âŒ Falha ao iniciar servidor")
        sys.exit(1)
    
    if args.server_only:
        print(f"ğŸ–¥ï¸ Servidor rodando em http://{args.host}:{args.port}")
        print("Pressione Ctrl+C para parar...")
        try:
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            print("\nğŸ‘‹ Encerrando servidor...")
    else:
        # Inicia shell interativo
        agent.interactive_shell()
    
    agent.stop_server()

if __name__ == "__main__":
    main()